#!/usr/bin/env python3
"""
Milo Bitcoin RAG - å•GPUé¡ºåºæ‰¹é‡æ–‡æ¡£å¤„ç†å™¨
ä¸“ä¸ºå•GPUç¯å¢ƒè®¾è®¡ï¼Œé¡ºåºå¤„ç†PDFæ–‡æ¡£ï¼Œè‡ªåŠ¨GPUå†…å­˜ç®¡ç†

åŠŸèƒ½ç‰¹æ€§:
- å•GPUé¡ºåºå¤„ç†ï¼Œé¿å…CUDAå†…å­˜å†²çª
- è‡ªåŠ¨å‘ç°rag_dataç›®å½•ä¸‹çš„PDFæ–‡æ¡£
- ä½¿ç”¨ç”Ÿäº§ç¯å¢ƒgranite_docling.pyå¤„ç†ç®¡é“
- æ™ºèƒ½è¾“å‡ºç®¡ç†å’Œè´¨é‡æ£€æŸ¥
- å¤„ç†è¿›åº¦è·Ÿè¸ªå’Œé”™è¯¯å¤„ç†

ä½¿ç”¨æ–¹æ³•:
    python scripts/batch_process_docs.py [é€‰é¡¹]

ç¤ºä¾‹:
    python scripts/batch_process_docs.py                           # å¤„ç†æ‰€æœ‰PDF
    python scripts/batch_process_docs.py --scan-only               # ä»…æ‰«ææ–‡æ¡£
    python scripts/batch_process_docs.py --category authoritative  # ä»…å¤„ç†æƒå¨æ–‡æ¡£
    python scripts/batch_process_docs.py --force                   # å¼ºåˆ¶é‡æ–°å¤„ç†
"""

import os
import sys
import argparse
import subprocess
import time
from datetime import datetime
from pathlib import Path
from typing import List, Optional, Tuple

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))

try:
    from scripts.utils import DocumentScanner, QualityChecker
    from scripts.utils.file_scanner import DocumentInfo
    from scripts.utils.quality_checker import QualityReport
except ImportError as e:
    print(f"Import error: {e}")
    print("Please run from project root directory")
    sys.exit(1)


class SingleGPUBatchProcessor:
    """å•GPUé¡ºåºæ‰¹é‡å¤„ç†å™¨"""

    def __init__(self, rag_data_path: str = "rag_data"):
        """
        åˆå§‹åŒ–å¤„ç†å™¨

        Args:
            rag_data_path: RAGæ•°æ®ç›®å½•è·¯å¾„
        """
        self.rag_data_path = Path(rag_data_path)
        self.sources_path = self.rag_data_path / "rag_sources"
        self.processed_path = self.rag_data_path / "rag_sources" / "processed"

        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.chunks_dir = self.processed_path / "chunks"
        self.metadata_dir = self.processed_path / "metadata"
        self.logs_dir = Path("logs") / "processing"

        for dir_path in [self.chunks_dir, self.metadata_dir, self.logs_dir]:
            dir_path.mkdir(parents=True, exist_ok=True)

        # åˆå§‹åŒ–å·¥å…·
        self.scanner = DocumentScanner(str(self.rag_data_path))
        self.quality_checker = QualityChecker()

        # granite_doclingè„šæœ¬è·¯å¾„ï¼ˆç”Ÿäº§ç¯å¢ƒç‰ˆæœ¬ï¼‰
        self.granite_script = Path("scripts/granite_docling.py")
        if not self.granite_script.exists():
            raise FileNotFoundError(f"Granite script not found: {self.granite_script}")

        # å¤„ç†ç»Ÿè®¡
        self.stats = {
            'total_found': 0,
            'processed': 0,
            'skipped': 0,
            'failed': 0,
            'quality_passed': 0,
            'quality_failed': 0
        }

        # åˆå§‹åŒ–æ—¥å¿—
        self._setup_logging()

    def _setup_logging(self):
        """è®¾ç½®æ—¥å¿—æ–‡ä»¶"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.log_file = self.logs_dir / f"batch_processing_{timestamp}.log"
        print(f"ğŸ“‹ Log file: {self.log_file}")

    def _log(self, message: str, level: str = "INFO"):
        """è®°å½•æ—¥å¿—"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        log_entry = f"[{timestamp}] {level}: {message}"

        print(log_entry)

        # å†™å…¥æ—¥å¿—æ–‡ä»¶
        with open(self.log_file, 'a', encoding='utf-8') as f:
            f.write(log_entry + "\n")

    def scan_documents(self, category: Optional[str] = None) -> List[DocumentInfo]:
        """
        æ‰«æPDFæ–‡æ¡£

        Args:
            category: å¯é€‰çš„æ–‡æ¡£ç±»åˆ«è¿‡æ»¤ ('authoritative' æˆ– 'supplementary')

        Returns:
            PDFæ–‡æ¡£ä¿¡æ¯åˆ—è¡¨
        """
        self._log("Starting document scan...")

        if category:
            all_docs = self.scanner.scan_by_category(category)
        else:
            all_docs = self.scanner.scan_all_documents()

        # ä»…ä¿ç•™PDFæ–‡æ¡£
        pdf_docs = [doc for doc in all_docs if doc.format == 'PDF']

        self._log(f"Found {len(pdf_docs)} PDF documents")
        if category:
            self._log(f"Filtered by category: {category}")

        # æ˜¾ç¤ºæ–‡æ¡£åˆ—è¡¨
        for i, doc in enumerate(pdf_docs, 1):
            self._log(f"  {i}. {doc.filename} ({doc.category}/{doc.subcategory})")

        self.stats['total_found'] = len(pdf_docs)
        return pdf_docs

    def process_documents(self, documents: List[DocumentInfo], force: bool = False) -> List[Tuple[DocumentInfo, bool, Optional[QualityReport]]]:
        """
        é¡ºåºå¤„ç†PDFæ–‡æ¡£

        Args:
            documents: è¦å¤„ç†çš„æ–‡æ¡£åˆ—è¡¨
            force: æ˜¯å¦å¼ºåˆ¶é‡æ–°å¤„ç†å·²å­˜åœ¨çš„æ–‡ä»¶

        Returns:
            å¤„ç†ç»“æœåˆ—è¡¨ (æ–‡æ¡£ä¿¡æ¯, æ˜¯å¦æˆåŠŸ, è´¨é‡æŠ¥å‘Š)
        """
        if not documents:
            self._log("No documents to process", "WARNING")
            return []

        self._log(f"Starting single-GPU sequential processing of {len(documents)} documents")
        results = []

        for i, doc in enumerate(documents, 1):
            self._log(f"\n{'='*60}")
            self._log(f"Processing document {i}/{len(documents)}: {doc.filename}")
            self._log(f"{'='*60}")

            try:
                success, quality_report, output_file = self._process_single_document(doc, force)
                results.append((doc, success, quality_report))

                if success:
                    self.stats['processed'] += 1
                    if quality_report and quality_report.total_score >= 60.0:
                        self.stats['quality_passed'] += 1
                    else:
                        self.stats['quality_failed'] += 1

                    self._log(f"âœ… Successfully processed: {doc.filename}")
                    self._log(f"   Output: {output_file}")
                else:
                    self.stats['failed'] += 1
                    self._log(f"âŒ Failed to process: {doc.filename}", "ERROR")

                # GPUé™æ¸©é—´éš”ï¼ˆå¯é€‰ï¼‰
                if i < len(documents):  # ä¸æ˜¯æœ€åä¸€ä¸ªæ–‡æ¡£
                    self._log("â¸ï¸  GPU cooling interval (2 seconds)...")
                    time.sleep(2)

            except Exception as e:
                self._log(f"Unexpected error processing {doc.filename}: {e}", "ERROR")
                results.append((doc, False, None))
                self.stats['failed'] += 1

        self._log(f"\nğŸ‰ Batch processing completed!")
        self._log(f"Processed: {self.stats['processed']}, Failed: {self.stats['failed']}")

        return results

    def _process_single_document(self, doc: DocumentInfo, force: bool = False) -> Tuple[bool, Optional[QualityReport], Optional[str]]:
        """
        å¤„ç†å•ä¸ªPDFæ–‡æ¡£

        Args:
            doc: æ–‡æ¡£ä¿¡æ¯
            force: æ˜¯å¦å¼ºåˆ¶é‡æ–°å¤„ç†

        Returns:
            (æ˜¯å¦æˆåŠŸ, è´¨é‡æŠ¥å‘Š, è¾“å‡ºæ–‡ä»¶è·¯å¾„)
        """
        # æ„å»ºé¢„æœŸçš„è¾“å‡ºæ–‡ä»¶è·¯å¾„
        expected_output = self._get_expected_output_path(doc)

        # æ£€æŸ¥æ˜¯å¦å·²å¤„ç†
        if not force and expected_output.exists():
            self._log(f"â­ï¸  Skipping {doc.filename} - already processed")
            self.stats['skipped'] += 1
            return True, None, str(expected_output)

        # ä½¿ç”¨ç”Ÿäº§ç¯å¢ƒ granite_docling.py å¤„ç†æ–‡æ¡£
        self._log(f"ğŸ”„ Calling production granite_docling.py for {doc.filename}")

        try:
            # æ„å»ºå¤„ç†å‘½ä»¤
            cmd = [
                "python",
                str(self.granite_script),
                doc.path,
                "--output-dir", str(self.chunks_dir)
            ]

            self._log(f"Command: {' '.join(cmd)}")

            start_time = time.time()
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=600,  # 10åˆ†é’Ÿè¶…æ—¶
                cwd=str(Path.cwd())  # ç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œ
            )

            elapsed = time.time() - start_time

            if result.returncode != 0:
                self._log(f"âŒ Granite processing failed: {result.stderr}", "ERROR")
                return False, None, None

            self._log(f"âœ… Granite processing completed in {elapsed:.1f}s")

            # ä»è¾“å‡ºä¸­æå–ç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„
            output_file = self._extract_output_file_from_result(result.stdout, doc)
            if not output_file:
                self._log(f"âŒ Could not determine output file for {doc.filename}", "ERROR")
                return False, None, None

            # è´¨é‡æ£€æŸ¥
            quality_report = self.quality_checker.check_document_quality(output_file)
            self._save_quality_report(quality_report, doc)

            self._log(f"ğŸ“Š Quality score: {quality_report.total_score:.1f}/100")

            return True, quality_report, output_file

        except subprocess.TimeoutExpired:
            self._log(f"â° Processing timeout for {doc.filename}", "ERROR")
            return False, None, None
        except Exception as e:
            self._log(f"ğŸ’¥ Processing error for {doc.filename}: {e}", "ERROR")
            return False, None, None

    def _get_expected_output_path(self, doc: DocumentInfo) -> Path:
        """è·å–é¢„æœŸçš„è¾“å‡ºæ–‡ä»¶è·¯å¾„"""
        input_filename = Path(doc.path).stem
        return self.chunks_dir / f"{input_filename}_processed.md"

    def _extract_output_file_from_result(self, stdout: str, doc: DocumentInfo) -> Optional[str]:
        """ä»granite_doclingçš„è¾“å‡ºä¸­æå–ç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„"""
        # æŸ¥æ‰¾ "RESULT_FILE:" è¡Œ
        for line in stdout.split('\n'):
            if 'RESULT_FILE:' in line:
                return line.split('RESULT_FILE:')[1].strip()

        # å›é€€æ–¹æ¡ˆï¼šæ£€æŸ¥é¢„æœŸä½ç½®
        expected = self._get_expected_output_path(doc)
        if expected.exists():
            return str(expected)

        return None

    def _save_quality_report(self, report: QualityReport, doc: DocumentInfo):
        """ä¿å­˜è´¨é‡æŠ¥å‘Šåˆ°metadataç›®å½•"""
        try:
            # æ„å»ºå…ƒæ•°æ®æ–‡ä»¶è·¯å¾„
            relative_path = Path(doc.path).relative_to(self.sources_path)
            metadata_file = self.metadata_dir / relative_path.with_suffix('.json')

            # ç¡®ä¿ç›®å½•å­˜åœ¨
            metadata_file.parent.mkdir(parents=True, exist_ok=True)

            # ä¿å­˜æŠ¥å‘Š
            import json
            report_data = {
                'file_path': report.file_path,
                'total_score': report.total_score,
                'content_length': report.content_length,
                'line_count': report.line_count,
                'issues': report.issues,
                'strengths': report.strengths,
                'metadata': report.metadata,
                'processed_at': datetime.now().isoformat()
            }

            with open(metadata_file, 'w', encoding='utf-8') as f:
                json.dump(report_data, f, indent=2, ensure_ascii=False)

            self._log(f"ğŸ’¾ Saved quality report: {metadata_file.name}")

        except Exception as e:
            self._log(f"âš ï¸  Failed to save quality report for {doc.filename}: {e}", "WARNING")

    def generate_summary_report(self) -> str:
        """ç”Ÿæˆå¤„ç†æ‘˜è¦æŠ¥å‘Š"""
        return f"""
ğŸ“Š Single-GPU Batch Processing Summary
{'='*60}
Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

ğŸ“ˆ Processing Statistics:
  â€¢ Total PDF Documents Found: {self.stats['total_found']}
  â€¢ Successfully Processed: {self.stats['processed']}
  â€¢ Skipped (Already Processed): {self.stats['skipped']}
  â€¢ Failed: {self.stats['failed']}

ğŸ“‹ Quality Control:
  â€¢ Quality Checks Passed: {self.stats['quality_passed']}
  â€¢ Quality Checks Failed: {self.stats['quality_failed']}

ğŸ“ Output Locations:
  â€¢ Processed Documents: {self.chunks_dir}
  â€¢ Quality Reports: {self.metadata_dir}
  â€¢ Processing Logs: {self.log_file}

ğŸ¯ GPU Processing:
  â€¢ Sequential processing (no CUDA conflicts)
  â€¢ Automatic GPU memory cleanup per document
  â€¢ 2-second cooling intervals between documents

âœ… Processing Complete!
"""


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='Milo Bitcoin RAG - Single GPU Batch Document Processor',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__
    )

    parser.add_argument(
        '--scan-only',
        action='store_true',
        help='ä»…æ‰«ææ–‡æ¡£ï¼Œä¸è¿›è¡Œå¤„ç†'
    )

    parser.add_argument(
        '--category',
        choices=['authoritative', 'supplementary'],
        help='ä»…å¤„ç†æŒ‡å®šç±»åˆ«çš„æ–‡æ¡£'
    )

    parser.add_argument(
        '--force',
        action='store_true',
        help='å¼ºåˆ¶é‡æ–°å¤„ç†æ‰€æœ‰æ–‡æ¡£ï¼ˆå¿½ç•¥å·²å­˜åœ¨çš„æ–‡ä»¶ï¼‰'
    )

    parser.add_argument(
        '--rag-data',
        default='rag_data',
        help='RAGæ•°æ®ç›®å½•è·¯å¾„ï¼ˆé»˜è®¤: rag_dataï¼‰'
    )

    args = parser.parse_args()

    try:
        print("ğŸš€ Milo Bitcoin RAG - Single GPU Batch Processor")
        print("="*60)

        # åˆå§‹åŒ–å¤„ç†å™¨
        processor = SingleGPUBatchProcessor(args.rag_data)

        # æ‰«ææ–‡æ¡£
        documents = processor.scan_documents(args.category)

        if args.scan_only:
            print(f"\nğŸ“Š Scan Results: Found {len(documents)} PDF documents")
            return

        if not documents:
            print("âš ï¸  No PDF documents found to process.")
            return

        # ç¡®è®¤å¤„ç†
        print(f"\nğŸ¯ Ready to process {len(documents)} PDF documents")
        if not args.force:
            response = input("Continue? (y/N): ").strip().lower()
            if response != 'y':
                print("âŒ Processing cancelled by user")
                return

        # å¤„ç†æ–‡æ¡£
        results = processor.process_documents(documents, force=args.force)

        # ç”Ÿæˆå¹¶æ˜¾ç¤ºæ‘˜è¦æŠ¥å‘Š
        summary = processor.generate_summary_report()
        print(summary)

        # æ˜¾ç¤ºå¤±è´¥çš„æ–‡æ¡£
        failed_docs = [doc for doc, success, _ in results if not success]
        if failed_docs:
            print("âŒ Failed Documents:")
            for doc in failed_docs:
                print(f"  â€¢ {doc.filename}")

        # æ˜¾ç¤ºä½è´¨é‡æ–‡æ¡£
        low_quality_docs = [
            (doc, report) for doc, success, report in results
            if success and report and report.total_score < 60.0
        ]
        if low_quality_docs:
            print("âš ï¸  Low Quality Documents (< 60.0):")
            for doc, report in low_quality_docs:
                print(f"  â€¢ {doc.filename}: {report.total_score:.1f}/100")

    except KeyboardInterrupt:
        print("\n\nâš ï¸  Processing interrupted by user")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ Error: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()