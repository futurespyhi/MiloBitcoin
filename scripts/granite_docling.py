#!/usr/bin/env python3
"""
Granite Docling Production: ç”Ÿäº§ç¯å¢ƒæ ‡å‡†æ–‡æ¡£å¤„ç†å·¥å…·
ä½¿ç”¨Doclingæ ‡å‡†å¤„ç†ç®¡é“ï¼Œè¾“å‡ºåˆ°RAGç”Ÿäº§ç›®å½•
é€‚ç”¨äºæ‰¹é‡å¤„ç†å’ŒRAGç³»ç»Ÿæ„å»º

ä½¿ç”¨æ–¹æ³•:
    python scripts/granite_docling.py <pdf_file_path> [--output-dir <output_directory>]

ç¤ºä¾‹:
    python scripts/granite_docling.py rag_data/rag_sources/authoritative/whitepaper/bitcoin.pdf
    python scripts/granite_docling.py file.pdf --output-dir rag_data/rag_sources/processed/chunks
"""

import os
import sys
import time
import argparse
from datetime import datetime
from pathlib import Path


def process_pdf_standard(pdf_path, output_dir=None):
    """
    ä½¿ç”¨æ ‡å‡†å¤„ç†ç®¡é“å¤„ç†PDFæ–‡ä»¶

    Args:
        pdf_path: PDFæ–‡ä»¶è·¯å¾„
        output_dir: å¯é€‰çš„è¾“å‡ºç›®å½•ï¼Œé»˜è®¤ä¸º rag_data/rag_sources/processed/chunks

    Returns:
        (æˆåŠŸæ ‡å¿—, ç»“æœå­—å…¸)
    """
    print(f"ğŸ”„ Processing with standard pipeline: {pdf_path}")

    try:
        from docling.document_converter import DocumentConverter

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(pdf_path):
            print(f"âŒ PDF file not found: {pdf_path}")
            return False, None

        print(f"âœ… Found PDF file: {pdf_path}")

        # åˆå§‹åŒ–æ ‡å‡†DocumentConverter
        print("   Initializing DocumentConverter...")
        converter = DocumentConverter()  # ä½¿ç”¨é»˜è®¤æ ‡å‡†è®¾ç½®

        print("   Starting document conversion...")
        start_time = time.time()

        # æ‰§è¡Œè½¬æ¢
        result = converter.convert(source=pdf_path)
        doc = result.document

        elapsed = time.time() - start_time
        print(f"âœ… Conversion successful ({elapsed:.1f}s)")

        # å¯¼å‡ºåˆ°Markdown
        print("   Exporting to Markdown...")
        markdown_content = doc.export_to_markdown()

        # ç¡®å®šè¾“å‡ºç›®å½•å’Œæ–‡ä»¶å
        if output_dir is None:
            # é»˜è®¤è¾“å‡ºåˆ°RAGç”Ÿäº§ç›®å½•
            output_dir = Path("rag_data/rag_sources/processed/chunks")
        else:
            output_dir = Path(output_dir)

        output_dir.mkdir(parents=True, exist_ok=True)

        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶åï¼ˆä¿æŒç®€æ´ï¼Œé€‚åˆç”Ÿäº§ç¯å¢ƒï¼‰
        input_filename = Path(pdf_path).stem
        output_file = output_dir / f"{input_filename}_processed.md"

        # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œæ·»åŠ æ—¶é—´æˆ³é¿å…è¦†ç›–
        if output_file.exists():
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = output_dir / f"{input_filename}_processed_{timestamp}.md"

        # ä¿å­˜ç»“æœ
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(markdown_content)

        print(f"   ğŸ’¾ Saved: {output_file}")
        print(f"   ğŸ“Š Content length: {len(markdown_content)} characters")

        # åˆ†æå†…å®¹è´¨é‡
        lines = markdown_content.split('\n')
        headers = [line for line in lines if line.startswith('#')]

        print(f"   ğŸ“‘ Total lines: {len(lines)}")
        print(f"   ğŸ·ï¸  Headers found: {len(headers)}")

        # æ£€æŸ¥å¸¸è§æŠ€æœ¯å…³é”®è¯
        key_terms = ['Bitcoin', 'blockchain', 'cryptocurrency', 'peer-to-peer', 'cryptographic',
                    'transaction', 'network', 'protocol', 'algorithm', 'hash', 'lightning',
                    'payment', 'channel', 'node', 'consensus', 'mining', 'wallet', 'signature']
        found_terms = [term for term in key_terms if term.lower() in markdown_content.lower()]
        print(f"   ğŸ” Key terms found: {len(found_terms)}/{len(key_terms)} - {found_terms[:5]}")

        return True, {
            'content': markdown_content,
            'output_file': str(output_file),
            'processing_time': elapsed,
            'content_length': len(markdown_content),
            'lines_count': len(lines),
            'headers_count': len(headers),
            'key_terms': found_terms
        }

    except Exception as e:
        print(f"âŒ Standard processing failed: {e}")
        import traceback
        print(f"   Traceback: {traceback.format_exc()}")
        return False, None


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='Granite Docling Production: ç”Ÿäº§ç¯å¢ƒæ ‡å‡†æ–‡æ¡£å¤„ç†å·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__
    )

    parser.add_argument('pdf_file', help='PDFæ–‡ä»¶è·¯å¾„')
    parser.add_argument(
        '--output-dir',
        help='è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: rag_data/rag_sources/processed/chunksï¼‰'
    )
    parser.add_argument(
        '--verbose', '-v',
        action='store_true',
        help='æ˜¾ç¤ºè¯¦ç»†è¾“å‡º'
    )

    args = parser.parse_args()

    # æ‰“å°å·¥å…·ä¿¡æ¯
    print("ğŸš€ Granite Docling Production - RAG Document Processor")
    print("=" * 60)
    print(f"ğŸ“ Input file: {args.pdf_file}")
    print(f"ğŸ“‚ Output dir: {args.output_dir or 'rag_data/rag_sources/processed/chunks'}")
    print(f"â° Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    # å¤„ç†PDFæ–‡ä»¶
    success, result = process_pdf_standard(args.pdf_file, args.output_dir)

    if success:
        print("\n" + "=" * 60)
        print("ğŸ‰ Processing completed successfully!")
        print(f"   ğŸ“„ Output file: {result['output_file']}")
        print(f"   â±ï¸  Processing time: {result['processing_time']:.1f} seconds")
        print(f"   ğŸ“Š Content stats:")
        print(f"      - Length: {result['content_length']:,} characters")
        print(f"      - Lines: {result['lines_count']:,}")
        print(f"      - Headers: {result['headers_count']}")
        print(f"      - Key terms: {len(result['key_terms'])}")

        if args.verbose:
            print(f"\nğŸ” Found key terms: {result['key_terms']}")

        # è¾“å‡ºé€‚åˆæ‰¹é‡å¤„ç†è„šæœ¬è§£æçš„ç»“æœ
        print(f"\nğŸ“¤ RESULT_FILE: {result['output_file']}")

        return 0
    else:
        print("\n" + "=" * 60)
        print("âŒ Processing failed!")
        print("ğŸ’¡ Please check the PDF file path and try again.")
        return 1


if __name__ == "__main__":
    sys.exit(main())